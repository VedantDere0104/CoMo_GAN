{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoMo_GAN_Version_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Wmz623eNvhP7c0BrX7EKb2RIykuyFOLs",
      "authorship_tag": "ABX9TyNFoVsQLD/Yu2eN6iA8FLDQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VedantDere0104/CoMo_GAN/blob/main/CoMo_GAN_Version_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH-ARkm2NKDY"
      },
      "source": [
        "####"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "590OpPH6NOzp"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn\r\n",
        "from torchsummary import summary\r\n",
        "from torchvision import transforms\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from tqdm.auto import tqdm\r\n",
        "from torchvision.utils import make_grid\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torchvision"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzFegorNNsyi"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PieaDcZB_LID"
      },
      "source": [
        "in_channels = 3\r\n",
        "out_channels = 3\r\n",
        "out_channels_disc = 1\r\n",
        "z_dim = 512"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVIQK31q8jUs"
      },
      "source": [
        "\r\n",
        "def show_tensor_images(image_tensor, num_images=2, size=(3 , 512 , 512) , switch = False):\r\n",
        "  image_shifted = image_tensor\r\n",
        "  #print(image_shifted)\r\n",
        "  image_unflat = image_shifted.detach().cpu().view(-1, *size)\r\n",
        "  #print(image_unflat)\r\n",
        "  image_grid = make_grid(image_unflat[:num_images], nrow=2 , normalize=False)\r\n",
        "  #print(image_grid)\r\n",
        "  if switch:\r\n",
        "    image_grid = image_grid * 255.0\r\n",
        "  plt.imshow(image_grid.permute(1, 2, 0).squeeze())\r\n",
        "  plt.show()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4ZLEQ9C8lqs"
      },
      "source": [
        "def crop(image, new_shape):\r\n",
        "    middle_height = image.shape[2] // 2\r\n",
        "    middle_width = image.shape[3] // 2\r\n",
        "    starting_height = middle_height - new_shape[2] // 2\r\n",
        "    final_height = starting_height + new_shape[2]\r\n",
        "    starting_width = middle_width - new_shape[3] // 2\r\n",
        "    final_width = starting_width + new_shape[3]\r\n",
        "    cropped_image = image[:, :, starting_height:final_height, starting_width:final_width]\r\n",
        "    return cropped_image"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipzxf0zEN0sl"
      },
      "source": [
        "class Conv(nn.Module):\r\n",
        "  def __init__(self , \r\n",
        "               in_channels , \r\n",
        "               out_channels , \r\n",
        "               kernel_size = (2 , 2) , \r\n",
        "               stride = (2 , 2) , \r\n",
        "               padding = 0 , \r\n",
        "               use_norm = True , \r\n",
        "               use_activation = True , \r\n",
        "               use_dropout = False , \r\n",
        "               activation = 'lreu'):\r\n",
        "    super(Conv , self).__init__()\r\n",
        "\r\n",
        "    self.use_norm = use_norm\r\n",
        "    self.use_activation = use_activation\r\n",
        "    self.use_dropout = use_dropout\r\n",
        "    self.activation = activation\r\n",
        "\r\n",
        "    self.conv1 = nn.Conv2d(in_channels , out_channels , kernel_size , stride , padding , padding_mode='reflect')\r\n",
        "    \r\n",
        "    if self.use_norm:\r\n",
        "      self.norm = nn.InstanceNorm2d(out_channels)\r\n",
        "    if self.use_activation:\r\n",
        "      if self.activation == 'lrelu':\r\n",
        "        self.activation_ = nn.LeakyReLU(0.2)\r\n",
        "      else :\r\n",
        "        self.activation_ = nn.ReLU(inplace=True)\r\n",
        "    if self.use_dropout:\r\n",
        "      self.dropout = nn.Dropout()\r\n",
        "  \r\n",
        "  def forward(self , x):\r\n",
        "    x = self.conv1(x)\r\n",
        "    if self.use_norm:\r\n",
        "      x = self.norm(x)\r\n",
        "    if self.use_activation:\r\n",
        "      x = self.activation_(x)\r\n",
        "    if self.use_dropout:\r\n",
        "      x = self.dropout(x)\r\n",
        "\r\n",
        "    return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVtDLzPJPJIq"
      },
      "source": [
        "conv = Conv(3 , 32).to(device)\r\n",
        "summary(conv , (3 , 512 , 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bmET2DEPbMA"
      },
      "source": [
        "class ConvT(nn.Module):\r\n",
        "  def __init__(self , \r\n",
        "               in_channels , \r\n",
        "               out_channels , \r\n",
        "               kernel_size = (2 , 2) , \r\n",
        "               stride = (2 , 2) , \r\n",
        "               padding = 0 , \r\n",
        "               use_norm = True , \r\n",
        "               use_activation = True , \r\n",
        "               use_dropout = False , \r\n",
        "               activation = 'reu'):\r\n",
        "    super(ConvT , self).__init__()\r\n",
        "\r\n",
        "    self.use_norm = use_norm\r\n",
        "    self.use_activation = use_activation\r\n",
        "    self.use_dropout = use_dropout\r\n",
        "    self.activation = activation\r\n",
        "\r\n",
        "    self.convT1 = nn.ConvTranspose2d(in_channels , out_channels , kernel_size , stride , padding )\r\n",
        "    \r\n",
        "    if self.use_norm:\r\n",
        "      self.norm = nn.InstanceNorm2d(out_channels)\r\n",
        "    if self.use_activation:\r\n",
        "      if self.activation == 'lrelu':\r\n",
        "        self.activation_ = nn.LeakyReLU(0.2)\r\n",
        "      else :\r\n",
        "        self.activation_ = nn.ReLU(inplace=True)\r\n",
        "    if self.use_dropout:\r\n",
        "      self.dropout = nn.Dropout()\r\n",
        "  \r\n",
        "  def forward(self , x):\r\n",
        "    x = self.convT1(x)\r\n",
        "    if self.use_norm:\r\n",
        "      x = self.norm(x)\r\n",
        "    if self.use_activation:\r\n",
        "      x = self.activation_(x)\r\n",
        "    if self.use_dropout:\r\n",
        "      x = self.dropout(x)\r\n",
        "\r\n",
        "    return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxJ7J2wNP3_J"
      },
      "source": [
        "convT = ConvT(3 , 32).to(device)\r\n",
        "summary(convT , (3 , 256 , 256))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f5x1AXsRYXW"
      },
      "source": [
        "class Linear(nn.Module):\r\n",
        "  def __init__(self ,\r\n",
        "               in_channels ,\r\n",
        "               out_channels , \r\n",
        "               kernel_size = (2, 2) , \r\n",
        "               stride = (2 , 2) ,\r\n",
        "               padding = 0 ,\r\n",
        "               use_norm = True , \r\n",
        "               use_activation = True , \r\n",
        "               activation = 'lrelu'):\r\n",
        "    super(Linear , self).__init__()\r\n",
        "\r\n",
        "    self.use_norm = use_norm\r\n",
        "    self.use_activation = use_activation\r\n",
        "    self.activation = activation\r\n",
        "\r\n",
        "    self.linear1 = nn.Linear(in_channels , out_channels)\r\n",
        "    \r\n",
        "    if self.use_norm:\r\n",
        "      self.norm = nn.BatchNorm1d(out_channels)\r\n",
        "    if self.use_activation:\r\n",
        "      if self.activation == 'lrelu':\r\n",
        "        self.activation_ = nn.LeakyReLU(0.2)\r\n",
        "      else:\r\n",
        "        self.activation_ = nn.ReLU(inplace=True)\r\n",
        "  \r\n",
        "  def forward(self ,x):\r\n",
        "    x = self.linear1(x)\r\n",
        "    if self.use_norm:\r\n",
        "      x = self.norm(x)\r\n",
        "    if self.use_activation:\r\n",
        "      x = self.activation_(x)\r\n",
        "\r\n",
        "    return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77BNh6SCScqq"
      },
      "source": [
        "linear = Linear(3 , 32).to(device)\r\n",
        "x = torch.randn(3 , 3).to(device)\r\n",
        "z = linear(x)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d0T-9HlP8y2"
      },
      "source": [
        "class Generator_Encoder(nn.Module):\r\n",
        "  def __init__(self, \r\n",
        "                in_channels , \r\n",
        "               out_channels, \r\n",
        "               hidden_dim = 32 , \r\n",
        "               ):\r\n",
        "    super(Generator_Encoder , self).__init__()\r\n",
        "\r\n",
        "    self.conv1 = Conv(in_channels , hidden_dim , use_norm=False)\r\n",
        "    self.conv2 = Conv(hidden_dim , hidden_dim * 2)\r\n",
        "    self.conv3 = Conv(hidden_dim * 2 , hidden_dim * 4)\r\n",
        "    self.conv4 = Conv(hidden_dim * 4 , hidden_dim * 8)\r\n",
        "    self.conv5 = Conv(hidden_dim * 8 , hidden_dim * 16)\r\n",
        "    self.conv6 = Conv(hidden_dim * 16 , hidden_dim * 32)\r\n",
        "    self.conv7 = Conv(hidden_dim * 32 , hidden_dim * 32)\r\n",
        "\r\n",
        "    self.flatten = nn.Flatten()\r\n",
        "\r\n",
        "    self.linear1 = Linear(16384 , hidden_dim * 32)\r\n",
        "    self.linear2 = Linear(hidden_dim * 32 , hidden_dim * 32)\r\n",
        "    self.linear3 = Linear(hidden_dim * 32 , out_channels)\r\n",
        "    \r\n",
        "\r\n",
        "  def forward(self , x):\r\n",
        "    x = self.conv1(x)\r\n",
        "    x = self.conv2(x)\r\n",
        "    x = self.conv3(x)\r\n",
        "    x = self.conv4(x)\r\n",
        "    x = self.conv5(x)\r\n",
        "    x = self.conv6(x)\r\n",
        "    x = self.conv7(x)\r\n",
        "    x = self.flatten(x)\r\n",
        "    x = self.linear1(x)\r\n",
        "    x = self.linear2(x)\r\n",
        "    x = self.linear3(x)\r\n",
        "    return x.view(x.shape[0] , x.shape[1] , 1 , 1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yPwbJJzQ1iJ"
      },
      "source": [
        "encoder = Generator_Encoder(3 , 512).to(device)\r\n",
        "summary(encoder , (3 , 512 , 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzXu8b39Q9Bu"
      },
      "source": [
        "class HE(nn.Module):\r\n",
        "  def __init__(self ,\r\n",
        "               in_channels , \r\n",
        "               out_channels,  \r\n",
        "               hidden_dim = 32 ):\r\n",
        "    super(HE , self).__init__()\r\n",
        "\r\n",
        "    self.convT1 = ConvT(in_channels , hidden_dim)\r\n",
        "    self.convT2 = ConvT(hidden_dim , hidden_dim * 2)\r\n",
        "    self.convT3 = ConvT(hidden_dim * 2 , hidden_dim * 4)\r\n",
        "    self.convT4 = ConvT(hidden_dim *4 , hidden_dim * 8)\r\n",
        "\r\n",
        "    self.conv1 = Conv(hidden_dim * 8 , hidden_dim * 4)\r\n",
        "    self.conv2 = Conv(hidden_dim * 4 , hidden_dim * 2)\r\n",
        "    self.conv3 = Conv(hidden_dim * 2 , hidden_dim)\r\n",
        "    self.conv4 = Conv(hidden_dim , out_channels)\r\n",
        "\r\n",
        "  def forward(self,  x):\r\n",
        "    x = self.convT1(x)\r\n",
        "    x = self.convT2(x)\r\n",
        "    x = self.convT3(x)\r\n",
        "    x = self.convT4(x)\r\n",
        "    x = self.conv1(x)\r\n",
        "    x = self.conv2(x)\r\n",
        "    x = self.conv3(x)\r\n",
        "    x = self.conv4(x)\r\n",
        "    return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzKFXP9PalS5"
      },
      "source": [
        "he = HE(512 , 256).to(device)\r\n",
        "summary(he , (512 , 1 , 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yfP5KbT0ysZ"
      },
      "source": [
        "class FIN(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(FIN , self).__init__()\r\n",
        "\r\n",
        "  def forward(self , x , o):\r\n",
        "    norm = ((x - torch.mean(x))/ torch.var(x)) * self.FIN_parameters(o , switch = True) + self.FIN_parameters(o , switch= True , angle = 'sin')\r\n",
        "    return norm\r\n",
        "\r\n",
        "  def FIN_parameters(self , o , switch =False , angle = 'cos'):\r\n",
        "    a = torch.randn(*o.shape , requires_grad=True).to(device)\r\n",
        "    b = torch.randn(*o.shape , requires_grad=True).to(device)\r\n",
        "    if switch:\r\n",
        "      if angle == 'cos':\r\n",
        "        f = a * torch.cos(o) + b\r\n",
        "      else:\r\n",
        "        f = a * torch.sin(o) + b\r\n",
        "    else:\r\n",
        "      f = a * o + b\r\n",
        "    return f"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0gVo9tD29mh"
      },
      "source": [
        "x = torch.randn(2 , 3 , 512 , 512).to(device)\r\n",
        "o = torch.randn(1).to(device)\r\n",
        "fin = FIN().to(device)\r\n",
        "norm = fin(x , o)\r\n",
        "norm.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv-GlnvzcgtE"
      },
      "source": [
        "class DRB(nn.Module):\r\n",
        "  def __init__(self , \r\n",
        "               in_channels , \r\n",
        "               out_channels):\r\n",
        "    super(DRB , self).__init__()\r\n",
        "\r\n",
        "    self.he = HE(in_channels , out_channels)\r\n",
        "    self.FIN = FIN()\r\n",
        "    self.hem = HE(in_channels , out_channels)\r\n",
        "\r\n",
        "  def forward(self , x , o):\r\n",
        "    he = self.he(x)\r\n",
        "    fin = self.FIN(x , o)\r\n",
        "    hem = self.hem(x)\r\n",
        "    #print(he.shape , hem.shape)\r\n",
        "    hy = torch.cat([he , fin] , dim=1)\r\n",
        "    hy = torch.cat([hy , x] , dim=1)\r\n",
        "    hym = torch.cat([hem , fin] , dim=1)\r\n",
        "    hym = torch.cat([hym , x] , dim=1)\r\n",
        "    x = torch.cat([hy , hym] , dim=1)\r\n",
        "    return x"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otDh0FM7d2_G"
      },
      "source": [
        "x = torch.randn(3 , 512 , 1 , 1).to(device)\r\n",
        "o = torch.randn(1).to(device)\r\n",
        "drb = DRB(512 , 512).to(device)\r\n",
        "x= drb(x , o)\r\n",
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT_J2v7zeHwq"
      },
      "source": [
        "class Generator_Decoder(nn.Module):\r\n",
        "  def __init__(self , \r\n",
        "               in_channels , \r\n",
        "               out_channels , \r\n",
        "               hidden_dim = 32):\r\n",
        "    super(Generator_Decoder , self).__init__()\r\n",
        "\r\n",
        "    self.convT1 = ConvT(in_channels , hidden_dim)\r\n",
        "    self.convT2 = ConvT(hidden_dim , hidden_dim * 2)\r\n",
        "    self.convT3 = ConvT(hidden_dim * 2 , hidden_dim * 4)\r\n",
        "    self.convT4 = ConvT(hidden_dim * 4 , hidden_dim * 8)\r\n",
        "    self.convT5 = ConvT(hidden_dim * 8 , hidden_dim * 16)\r\n",
        "    self.convT6 = ConvT(hidden_dim * 16 , hidden_dim * 32)\r\n",
        "    self.convT7 = ConvT(hidden_dim * 32 , hidden_dim * 32)\r\n",
        "    self.convT8 = ConvT(hidden_dim * 32 , hidden_dim * 16)\r\n",
        "    self.convT9 = ConvT(hidden_dim * 16 , out_channels)\r\n",
        "\r\n",
        "  def forward(self , x):\r\n",
        "    x = self.convT1(x)\r\n",
        "    x = self.convT2(x)\r\n",
        "    x = self.convT3(x)\r\n",
        "    x = self.convT4(x)\r\n",
        "    x = self.convT5(x)\r\n",
        "    x = self.convT6(x)\r\n",
        "    x = self.convT7(x)\r\n",
        "    x = self.convT8(x)\r\n",
        "    x = self.convT9(x)\r\n",
        "\r\n",
        "    return x"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo7WawNBflrW"
      },
      "source": [
        "generator_decoder = Generator_Decoder(512 , 3).to(device)\r\n",
        "summary(generator_decoder , (512 , 1 , 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcHJTdhtfuMS"
      },
      "source": [
        "class Generator(nn.Module):\r\n",
        "  def __init__(self , \r\n",
        "               in_channels , \r\n",
        "               out_channels , \r\n",
        "               z_dim = 512 , \r\n",
        "               hidden_dim = 32):\r\n",
        "    super(Generator ,self).__init__()\r\n",
        "\r\n",
        "    self.encoder = Generator_Encoder(in_channels , z_dim)\r\n",
        "    self.drb = DRB(z_dim , z_dim)\r\n",
        "    self.decoder = Generator_Decoder((hidden_dim * 32 + z_dim) * 2 , out_channels)\r\n",
        "\r\n",
        "  def forward(self , x , o):\r\n",
        "    x = self.encoder(x)\r\n",
        "    h_ = self.drb(x , o)\r\n",
        "    y = self.decoder(h_)\r\n",
        "    return y"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G4q-6tPhMlO"
      },
      "source": [
        "x = torch.randn(2 , 3 , 512 , 512).to(device)\r\n",
        "o = torch.randn(1).to(device)\r\n",
        "generator = Generator(3 , 3).to(device)\r\n",
        "y = generator(x , o)\r\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLseDHDthSWC"
      },
      "source": [
        "class Discriminator(nn.Module):\r\n",
        "  def __init__(self , \r\n",
        "               in_channels , \r\n",
        "               out_channels):\r\n",
        "    super(Discriminator , self).__init__()\r\n",
        "\r\n",
        "    self.encoder = Generator_Encoder(in_channels , out_channels)\r\n",
        "\r\n",
        "  def forward(self , x):\r\n",
        "    x = self.encoder(x)\r\n",
        "    return x"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0BoVCinhsbu"
      },
      "source": [
        "discriminator = Discriminator(3 , 1).to(device)\r\n",
        "summary(discriminator , (3 , 512 , 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6806Xe4OxOpJ"
      },
      "source": [
        "class M_(nn.Module):\r\n",
        "  def __init__(self , \r\n",
        "               in_channels , \r\n",
        "               out_channels):\r\n",
        "    super(M_ , self).__init__()\r\n",
        "\r\n",
        "    self.generator_x = Generator(in_channels , out_channels)\r\n",
        "  def forward(self , x , x_ , o , o_):\r\n",
        "    x , _ = self.generator_x(x , o)\r\n",
        "    _ , x_ = self.generator_x(x_ , o_ )\r\n",
        "    return x , x_ "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzk8fowP7uG6"
      },
      "source": [
        "x = torch.randn(2 , 3 , 512 , 512).to(device)\r\n",
        "x_ = torch.randn_like(x)\r\n",
        "o = torch.randn(1).to(device)\r\n",
        "o_ = torch.randn_like(o)\r\n",
        "m = M_(3 , 3).to(device)\r\n",
        "x , x_ = m(x , x_ , o , o_)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3NHzXw7hy7T"
      },
      "source": [
        "class O_Net(nn.Module):\r\n",
        "  def __init__(self ,\r\n",
        "               in_channels , \r\n",
        "               out_channels):\r\n",
        "    super(O_Net , self).__init__()\r\n",
        "\r\n",
        "    self.discriminator_x = Discriminator(in_channels ,out_channels)\r\n",
        "    self.discriminator_y = Discriminator(in_channels ,out_channels)\r\n",
        "\r\n",
        "  def forward(self , x , x_):\r\n",
        "    o = self.discriminator_x(x)\r\n",
        "    o_ = self.discriminator_y(x)\r\n",
        "    delta = o - o_\r\n",
        "    return delta"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA7tE25aIBkV"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mECvcJf7iaS2"
      },
      "source": [
        "onet = O_Net(3 , 1).to(device)\r\n",
        "x = torch.randn(2 , 3 , 512 , 512).to(device)\r\n",
        "y = torch.randn_like(x)\r\n",
        "a = onet(x , y )\r\n",
        "a.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUAcsjQL79bu"
      },
      "source": [
        "generator_x = Generator(in_channels , out_channels , z_dim).to(device)\r\n",
        "generator_y = Generator(in_channels , out_channels , z_dim).to(device)\r\n",
        "discriminator_x = Discriminator(in_channels , out_channels_disc).to(device)\r\n",
        "discriminator_y = Discriminator(in_channels , out_channels_disc).to(device)\r\n",
        "o_net = O_Net(in_channels , out_channels_disc).to(device)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VcxOtqw_eqf"
      },
      "source": [
        "def weights_init(m):\r\n",
        "  if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\r\n",
        "    torch.nn.init.normal_(m.weight, 0.0, 0.02)\r\n",
        "  if isinstance(m, nn.BatchNorm2d):\r\n",
        "    torch.nn.init.normal(m.weight, 0.0, 0.02)\r\n",
        "    torch.nn.init.constant(m.bias, 0)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPJUwdhMBkM6"
      },
      "source": [
        "generator_x = generator_x.apply(weights_init)\r\n",
        "generator_y = generator_y.apply(weights_init)\r\n",
        "discriminator_x = discriminator_x.apply(weights_init)\r\n",
        "discriminator_y = discriminator_y.apply(weights_init)\r\n",
        "o_net = o_net.apply(weights_init)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc7aQ_FvBmH9"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\r\n",
        "l1_loss = nn.L1Loss()\r\n",
        "lambda_recon = 200"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x41vGC8OBoVl"
      },
      "source": [
        "n_epochs = 100\r\n",
        "input_dim = 3\r\n",
        "real_dim = 3\r\n",
        "display_step = 10\r\n",
        "batch_size = 2\r\n",
        "lr = 0.0002\r\n",
        "target_shape = 512\r\n",
        "\r\n",
        "betas = (0.5 , 0.999)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH65nGJhBqoI"
      },
      "source": [
        "\r\n",
        "transform = transforms.Compose([ transforms.ToTensor(), ])\r\n",
        "\r\n",
        "dataset = torchvision.datasets.ImageFolder(\"/content/drive/MyDrive/Maps/maps/\", transform=transform)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqUUEtxRBufG"
      },
      "source": [
        "\r\n",
        "mean_generator_loss = 0\r\n",
        "mean_discriminator_loss = 0\r\n",
        "dataloader = DataLoader(dataset , batch_size = batch_size , shuffle=True)\r\n",
        "cur_step = 0"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTTetlfqDelq"
      },
      "source": [
        "opt_generator_y = torch.optim.Adam(generator_y.parameters() , lr=lr , betas=betas)\r\n",
        "opt_generator_x = torch.optim.Adam(generator_x.parameters() , lr = lr , betas = betas)\r\n",
        "opt_discriminator_x = torch.optim.Adam(discriminator_x.parameters() , lr = lr , betas=betas)\r\n",
        "opt_discriminator_y = torch.optim.Adam(discriminator_y.parameters() , lr = lr , betas=betas)\r\n",
        "opt_o_net = torch.optim.Adam(o_net.parameters() , lr=lr , betas = betas)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PUezgpwDj29"
      },
      "source": [
        "def get_gen_loss(del_1 , del_2 , delta , criterion_loss , loss_m):\r\n",
        "  loss_g_o = torch.norm(del_1) + torch.norm(del_1 - delta)\r\n",
        "  loss_gt = torch.norm(del_2 - delta)\r\n",
        "  loss_o = loss_g_o + loss_gt\r\n",
        "\r\n",
        "  loss_generator = loss_o + criterion_loss + loss_m\r\n",
        "  return loss_generator\r\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ovw5wzi7l_D"
      },
      "source": [
        "def get_loss(fake , real  , criterion = criterion , l1_loss = l1_loss , lambda_recon = lambda_recon):\r\n",
        "  gen_loss = criterion(fake , real)\r\n",
        "  l1_loss = l1_loss(fake , real)\r\n",
        "  loss = gen_loss + lambda_recon *  l1_loss\r\n",
        "  return loss"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ymh1bzfFVSZ"
      },
      "source": [
        "for epoch in range(n_epochs):\r\n",
        "  for img , _ in tqdm(dataloader):\r\n",
        "    image_width = img.shape[3]\r\n",
        "    y = img[: , : , : , :image_width//2]\r\n",
        "    y = nn.functional.interpolate(y , size = target_shape)\r\n",
        "    x = img[: , : , : , image_width//2:]\r\n",
        "    x = nn.functional.interpolate(x , size = target_shape)\r\n",
        "    cur_batch_size = len(x)\r\n",
        "    x = x.to(device)\r\n",
        "    y = y.to(device)  \r\n",
        "    o = torch.randn(x.shape[0] , 1 , 1 , 1).to(device)\r\n",
        "    o_ = torch.randn_like(o)\r\n",
        "\r\n",
        "    #show_tensor_images(x)\r\n",
        "    #show_tensor_images(y)\r\n",
        "\r\n",
        "    opt_generator_x.zero_grad()\r\n",
        "    y_o  = generator_x(x , o)\r\n",
        "    loss_y_o = get_loss(y_o , y)\r\n",
        "    loss_y_o.backward()\r\n",
        "    opt_generator_x.step()\r\n",
        "\r\n",
        "    opt_discriminator_x.zero_grad()\r\n",
        "    with torch.no_grad():\r\n",
        "      y_o = generator_x(x , o)\r\n",
        "    disc_fake_pred = discriminator_x(y_o)\r\n",
        "    disc_real_pred = discriminator_x(y)\r\n",
        "    disc_loss = criterion(disc_fake_pred , torch.zeros_like(disc_fake_pred))\r\n",
        "    disc_real_pred_loss = criterion(y , torch.ones_like(y))\r\n",
        "    disc_loss = (disc_loss + disc_real_pred_loss)/2\r\n",
        "    disc_loss.backward()\r\n",
        "    opt_discriminator_x.step()\r\n",
        "\r\n",
        "    opt_generator_y.zero_grad()\r\n",
        "    x_o  = generator_y(y , o)\r\n",
        "    loss_x_o = get_loss(x_o , x)\r\n",
        "    loss_x_o.backward()\r\n",
        "    opt_generator_y.step()\r\n",
        "\r\n",
        "    opt_discriminator_y.zero_grad()\r\n",
        "    with torch.no_grad():\r\n",
        "      x_o  = generator_y(y , o)\r\n",
        "    disc_fake_pred_ = discriminator_y(x_o)\r\n",
        "    disc_real_pred_ = discriminator_y(x)\r\n",
        "    disc_loss_ = criterion(disc_fake_pred_ , torch.zeros_like(disc_fake_pred_))\r\n",
        "    disc_real_pred_loss_ = criterion(y , torch.ones_like(y))\r\n",
        "    disc_loss_ = (disc_loss_ + disc_real_pred_loss_)/2\r\n",
        "    disc_loss_.backward()\r\n",
        "    opt_discriminator_x.step()\r\n",
        "\r\n",
        "\r\n",
        "    generator_loss_ = (loss_y_o + loss_x_o)/2\r\n",
        "    discriminator_loss_ = (disc_loss + disc_loss_)/2\r\n",
        "\r\n",
        "    gen_loss_ = torch.tensor(generator_loss_ , requires_grad=True)\r\n",
        "\r\n",
        "    opt_o_net.zero_grad()\r\n",
        "    with torch.no_grad():\r\n",
        "      y_o  = generator_x(x , o)\r\n",
        "      x_o = generator_y(y , o)\r\n",
        "      y_o_ = generator_x(x , o_)\r\n",
        "      x_o_ = generator_y(y , o_)\r\n",
        "    delta_1 = o_net(y_o , x_o)\r\n",
        "    delta_2 = o_net(y_o_ , x_o_)\r\n",
        "    loss_1 = get_gen_loss(delta_1 , delta_2 , 0 , gen_loss_ , 0)\r\n",
        "    loss_1.backward()\r\n",
        "    opt_o_net.step()\r\n",
        "\r\n",
        "    mean_generator_loss = ((generator_loss_ + loss_1)/2) /display_step\r\n",
        "    mean_discriminator_loss = ((discriminator_loss_ + loss_1)/2) / display_step\r\n",
        "\r\n",
        "\r\n",
        "    if cur_step % display_step == 0:\r\n",
        "      if cur_step > 0:\r\n",
        "        print(f\"Epoch {epoch}: Step {cur_step}: Generator loss: {mean_generator_loss}, Discriminator loss: {mean_discriminator_loss}\")\r\n",
        "      else:\r\n",
        "        \r\n",
        "        #print(img_tensor.shape)\r\n",
        "        print(\"Pretrained initial state\")\r\n",
        "\r\n",
        "      \r\n",
        "      print('Y')\r\n",
        "      show_tensor_images(y, size=(real_dim, target_shape, target_shape) , switch=False)\r\n",
        "\r\n",
        "\r\n",
        "      print('X')\r\n",
        "      show_tensor_images(x, size=(real_dim, target_shape, target_shape) , switch=False)\r\n",
        "\r\n",
        "      print('y_o')\r\n",
        "      show_tensor_images(y_o, size=(real_dim, target_shape, target_shape) , switch= False)\r\n",
        "\r\n",
        "      print('x_o')\r\n",
        "      show_tensor_images(x_o, size=(real_dim, target_shape, target_shape) , switch= False)\r\n",
        "\r\n",
        "      print('y_o_')\r\n",
        "      show_tensor_images(y_o_, size=(input_dim, target_shape, target_shape) , switch=False)\r\n",
        "\r\n",
        "      print('x_o_')\r\n",
        "      show_tensor_images(x_o_, size=(real_dim, target_shape, target_shape) , switch=False)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "      mean_generator_loss = 0\r\n",
        "      mean_discriminator_loss = 0\r\n",
        "    cur_step += 1\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "296leBaeFv5W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}